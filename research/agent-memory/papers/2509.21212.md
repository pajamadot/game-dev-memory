# SGMem: Sentence Graph Memory for Long-Term Conversational Agents

- arXiv: 2509.21212
- URL: https://arxiv.org/abs/2509.21212v1
- PDF: https://arxiv.org/pdf/2509.21212v1
- Published: 2025-09-25T14:21:44Z
- Updated: 2025-09-25T14:21:44Z
- Categories: cs.CL, cs.IR
- Authors: Yaxiong Wu, Yongyue Zhang, Sheng Liang, Yong Liu

## Abstract

Long-term conversational agents require effective memory management to handle dialogue histories that exceed the context window of large language models (LLMs). Existing methods based on fact extraction or summarization reduce redundancy but struggle to organize and retrieve relevant information across different granularities of dialogue and generated memory. We introduce SGMem (Sentence Graph Memory), which represents dialogue as sentence-level graphs within chunked units, capturing associations across turn-, round-, and session-level contexts. By combining retrieved raw dialogue with generated memory such as summaries, facts and insights, SGMem supplies LLMs with coherent and relevant context for response generation. Experiments on LongMemEval and LoCoMo show that SGMem consistently improves accuracy and outperforms strong baselines in long-term conversational question answering.

## What This Adds (fill in)

- Problem:
- Memory mechanism (write/update/retrieve/forget):
- Evaluation / benchmarks:
- Failure modes / tradeoffs:

## How This Maps To game-dev-memory (fill in)

- What to store (tables/assets):
- Retrieval pattern:
- Evolution trigger:
- UI affordance: