# Agent Workflow Memory

- arXiv: 2409.07429
- URL: https://arxiv.org/abs/2409.07429v1
- PDF: https://arxiv.org/pdf/2409.07429v1
- Published: 2024-09-11T17:21:00Z
- Updated: 2024-09-11T17:21:00Z
- Categories: cs.CL
- Authors: Zora Zhiruo Wang, Jiayuan Mao, Daniel Fried, Graham Neubig

## Abstract

Despite the potential of language model-based agents to solve real-world tasks such as web navigation, current methods still struggle with long-horizon tasks with complex action trajectories. In contrast, humans can flexibly solve complex tasks by learning reusable task workflows from past experiences and using them to guide future actions. To build agents that can similarly benefit from this process, we introduce Agent Workflow Memory (AWM), a method for inducing commonly reused routines, i.e., workflows, and selectively providing workflows to the agent to guide subsequent generations. AWM flexibly applies to both offline and online scenarios, where agents induce workflows from training examples beforehand or from test queries on the fly. We experiment on two major web navigation benchmarks -- Mind2Web and WebArena -- that collectively cover 1000+ tasks from 200+ domains across travel, shopping, and social media, among others. AWM substantially improves the baseline results by 24.6% and 51.1% relative success rate on Mind2Web and WebArena while reducing the number of steps taken to solve WebArena tasks successfully. Furthermore, online AWM robustly generalizes in cross-task, website, and domain evaluations, surpassing baselines from 8.9 to 14.0 absolute points as train-test task distribution gaps widen.

## What This Adds (fill in)

- Problem: Agents struggle on long-horizon tasks with complex action trajectories; humans reuse learned workflows.
- Memory mechanism (write/update/retrieve/forget): Induce reusable workflows from past trajectories and selectively retrieve them to guide future action generation (offline and online).
- Evaluation / benchmarks: Mind2Web and WebArena; improves success rate and reduces steps.
- Failure modes / tradeoffs: Workflow induction quality matters; stale workflows can mislead under domain shift; needs relevance gating.

## How This Maps To game-dev-memory (fill in)

- What to store (tables/assets): Treat "workflows" as procedural memories: tool chains + constraints + expected evidence outputs, stored alongside raw session evidence.
- Retrieval pattern: Retrieve workflow templates by similarity to current task (plus engine/project filters), then retrieve supporting evidence chunks for each step.
- Evolution trigger: After successful sessions, promote the successful action trace into a workflow candidate; after failed sessions, mark workflow as risky/superseded.
- UI affordance: A "Workflows" panel that shows reusable playbooks (runbooks) with required artifacts (e.g., logs/traces) and one-click execution in the agent UI.
