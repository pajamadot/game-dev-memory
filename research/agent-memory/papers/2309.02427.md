# Cognitive Architectures for Language Agents

- arXiv: 2309.02427
- URL: https://arxiv.org/abs/2309.02427v3
- PDF: https://arxiv.org/pdf/2309.02427v3
- Published: 2023-09-05T17:56:20Z
- Updated: 2024-03-15T15:44:11Z
- Categories: cs.AI, cs.CL, cs.LG, cs.SC
- Authors: Theodore R. Sumers, Shunyu Yao, Karthik Narasimhan, Thomas L. Griffiths

## Abstract

Recent efforts have augmented large language models (LLMs) with external resources (e.g., the Internet) or internal control flows (e.g., prompt chaining) for tasks requiring grounding or reasoning, leading to a new class of language agents. While these agents have achieved substantial empirical success, we lack a systematic framework to organize existing agents and plan future developments. In this paper, we draw on the rich history of cognitive science and symbolic artificial intelligence to propose Cognitive Architectures for Language Agents (CoALA). CoALA describes a language agent with modular memory components, a structured action space to interact with internal memory and external environments, and a generalized decision-making process to choose actions. We use CoALA to retrospectively survey and organize a large body of recent work, and prospectively identify actionable directions towards more capable agents. Taken together, CoALA contextualizes today's language agents within the broader history of AI and outlines a path towards language-based general intelligence.

## What This Adds (fill in)

- Problem: The agent literature lacks a unifying framework for organizing designs and planning future agent capabilities.
- Memory mechanism (write/update/retrieve/forget): Proposes modular memory components + a structured action space for interacting with memory and the environment as part of decision making.
- Evaluation / benchmarks: Primarily a framework/surveying lens rather than a single benchmark contribution.
- Failure modes / tradeoffs: Conceptual framework; implementation quality depends on concrete memory actions, retrieval policies, and grounding.

## How This Maps To game-dev-memory (fill in)

- What to store (tables/assets): Define explicit memory modules (episodic, semantic, procedural) and keep the artifact store (R2) as the evidence backbone.
- Retrieval pattern: Treat "memory actions" as tools (search, open asset chunk, summarize session, link/supersede memory) so the agent can reason about memory operations explicitly.
- Evolution trigger: Make memory maintenance a planned action (end-of-session and scheduled jobs), not an implicit side effect.
- UI affordance: Present the memory action set in the UI so humans can understand and override ("why did it save this?", "why did it forget that?").
