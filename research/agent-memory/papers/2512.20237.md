# MemR$^3$: Memory Retrieval via Reflective Reasoning for LLM Agents

- arXiv: 2512.20237
- URL: https://arxiv.org/abs/2512.20237v1
- PDF: https://arxiv.org/pdf/2512.20237v1
- Published: 2025-12-23T10:49:42Z
- Updated: 2025-12-23T10:49:42Z
- Categories: cs.AI
- Authors: Xingbo Du, Loka Li, Duzhen Zhang, Le Song

## Abstract

Memory systems have been designed to leverage past experiences in Large Language Model (LLM) agents. However, many deployed memory systems primarily optimize compression and storage, with comparatively less emphasis on explicit, closed-loop control of memory retrieval. From this observation, we build memory retrieval as an autonomous, accurate, and compatible agent system, named MemR$^3$, which has two core mechanisms: 1) a router that selects among retrieve, reflect, and answer actions to optimize answer quality; 2) a global evidence-gap tracker that explicitly renders the answering process transparent and tracks the evidence collection process. This design departs from the standard retrieve-then-answer pipeline by introducing a closed-loop control mechanism that enables autonomous decision-making. Empirical results on the LoCoMo benchmark demonstrate that MemR$^3$ surpasses strong baselines on LLM-as-a-Judge score, and particularly, it improves existing retrievers across four categories with an overall improvement on RAG (+7.29%) and Zep (+1.94%) using GPT-4.1-mini backend, offering a plug-and-play controller for existing memory stores.

## What This Adds (fill in)

- Problem:
- Memory mechanism (write/update/retrieve/forget):
- Evaluation / benchmarks:
- Failure modes / tradeoffs:

## How This Maps To game-dev-memory (fill in)

- What to store (tables/assets):
- Retrieval pattern:
- Evolution trigger:
- UI affordance: